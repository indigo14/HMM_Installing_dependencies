{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# HMM stride segmentation - Prediction with pre-trained model\n\nThis example illustrates how a Hidden Markov Model (HMM) implemented by the\n:class:`~gaitmap.stride_segmentation.hmm.HmmStrideSegmentation` can be used to detect strides in a continuous signal of\nan IMU signal.\nThe used implementation is based on the work of Roth et al [1]_\n\n.. [1] Roth, N., K\u00fcderle, A., Ullrich, M., Gladow, T., Marxreiter F., Klucken, J., Eskofier, B. & Kluge F. (2021).\n   Hidden Markov Model based Stride Segmentation on Unsupervised Free-living Gait Data in Parkinson\u2019s Disease Patients.\n   Journal of NeuroEngineering and Rehabilitation, (JNER).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting some example data\n\nFor this we take some example data that contains the regular walking movement during a 2x20m walk test of a healthy\nsubject. The IMU signals are already rotated so that they align with the gaitmap SF coordinate system.\nThe data contains information from two sensors - one from the right and one from the left foot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gaitmap.example_data import get_healthy_example_imu_data\n\ndata = get_healthy_example_imu_data()\nsampling_rate_hz = 204.8\ndata.sort_index(axis=1).head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing the data\nThe HMM only makes use of the gyro information.\nFurther, if you use this model, your data is expected to be in the gaitmap body-frame to be able to use the\nsame model for the left and the right foot.\nTherefore, we need to transform the dataset into the body frame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gaitmap.utils.coordinate_conversion import convert_to_fbf\n\n# We use the `..._like` parameters to identify the data of the left and the right foot based on the name of the sensor.\nbf_data = convert_to_fbf(data, left_like=\"left_\", right_like=\"right_\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting a pre-trained model\nThis library ships with pre-trained models that can be directly used for prediction/ segmentation.\nIt is generated based on manually segmented strides from healthy participants and PD patients.\nWe can load the model a look at some of its parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gaitmap.stride_segmentation.hmm import PreTrainedRothSegmentationModel\n\nroth_hmm_model = PreTrainedRothSegmentationModel()\n\nprint(f\"Number of states, stride-model: {roth_hmm_model.stride_model.n_states:d}\")\nprint(f\"Number of states, transition-model: {roth_hmm_model.transition_model.n_states:d}\")\nnp.set_printoptions(precision=3, linewidth=180, suppress=True)\nprint(f\"Transition matrix:\\n{roth_hmm_model.model.dense_transition_matrix()[0:-2, 0:-2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicting hidden states / Stride borders\nTo use this model to actually segment the data, we wrap it in the `HmmStrideSegmentation` class.\nThis class provides a interface and post-processing similar to other Stride Segmentation algorithms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gaitmap.stride_segmentation.hmm import HmmStrideSegmentation\n\nhmm_seg = HmmStrideSegmentation(roth_hmm_model, snap_to_min_win_ms=300, snap_to_min_axis=\"gyr_ml\")\nhmm_seg = hmm_seg.segment(bf_data, sampling_rate_hz=sampling_rate_hz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspecting the results\nThe main output is the `stride_list_`, which contains the start and the end of all identified strides.\nAs we passed a dataset with two sensors, the output will be a dictionary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stride_list_left = hmm_seg.stride_list_[\"left_sensor\"]\nprint(f\"{len(stride_list_left)} strides were detected.\")\nstride_list_left.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get a better understanding of the results, we can plot additional information about the results.\nThe top row shows the `gyr_ml` axis with the segmented strides plotted on top.\nThey are postprocessed to snap to the closed data minimum.\nIn the second row the predicted hidden state sequence of the HMM is plotted (this is the transformed version, matching\nthe input signal).\nEach transition from the last (n=25) to the first (n=5) stride state marks a potential start/end of a stride.\nThe second plot shows the results in the feature space (which will depend on the feature space setting during the\ntraining step).\nHere this is a downsampled and filtered representative of the gyr_ml signal as well as its window based gradient.\nAll features are z-transformed (note we z-transform the new data independently from the training data).\nAgain, the predicted hidden state sequence is plotted together with the data.\n\nOnly the first couple of strides of the left foot are shown.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sensor = \"left_sensor\"\n\nfig, axs = plt.subplots(nrows=2, sharex=True, figsize=(10, 5))\naxs[0].set_title(\"gaitmap Body Frame Dataset\")\naxs[0].plot(bf_data.reset_index(drop=True)[sensor][\"gyr_ml\"])\nfor start, end in hmm_seg.stride_list_[\"left_sensor\"].to_numpy():\n    axs[0].axvline(start, c=\"r\")\n    axs[0].axvline(end, c=\"r\")\n    axs[0].axvspan(start, end, alpha=0.2)\naxs[0].set_ylabel(\"gyr-ml [deg/s]\")\n\naxs[1].set_title(\"Predicted Hidden State Sequence\")\naxs[1].plot(hmm_seg.hidden_state_sequence_[sensor])\nfor start, end in hmm_seg.matches_start_end_original_[sensor]:\n    axs[1].axvline(start, c=\"g\")\n    axs[1].axvline(end, c=\"g\")\n    axs[1].axvspan(start, end, alpha=0.2)\naxs[1].set_ylabel(\"Hidden State [N]\")\n\naxs[1].set_xlabel(\"Samples @ %d Hz\" % sampling_rate_hz)\nplt.xlim([0, 5000])\nfig.tight_layout()\nplt.show()\n\nfig, ax1 = plt.subplots(figsize=(10, 3))\nplt.title(\"HMM Feature Space\")\nax1.set_xlabel(f\"Samples Features Space @ {hmm_seg.model.feature_transform.sampling_rate_feature_space_hz} Hz\")\nax1.set_ylabel(\"Z-Transform [a.u.]\")\nfeature_space_date = hmm_seg.result_model_[sensor].feature_space_data_\nax1.plot(feature_space_date)\nax1.legend(feature_space_date.columns.to_list())\n\nax2 = ax1.twinx()\nax2.set_ylabel(\"Hidden State Sequence\", color=\"tab:green\")\nhidden_state_sequence_feature_space = hmm_seg.result_model_[sensor].hidden_state_sequence_feature_space_\nax2.plot(hidden_state_sequence_feature_space, color=\"tab:green\")\nax2.tick_params(axis=\"y\", labelcolor=\"tab:green\")\n\nplt.xlim([0, 500])\nfig.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}